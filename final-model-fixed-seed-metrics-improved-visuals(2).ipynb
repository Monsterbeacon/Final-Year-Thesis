{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7523308,"sourceType":"datasetVersion","datasetId":4382464},{"sourceId":8407122,"sourceType":"datasetVersion","datasetId":5002927}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.io as sio\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nimport warnings\nfrom sklearn.model_selection import train_test_split\nimport os\nimport sys\nimport shutil\nimport time\nimport pywt\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import Callback,ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Layer, LayerNormalization\nfrom keras.layers import GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, AveragePooling2D, MaxPooling2D\nfrom tensorflow.keras.layers import Conv1D, Conv2D, SeparableConv2D, DepthwiseConv2D\nfrom tensorflow.keras.layers import BatchNormalization, LayerNormalization, Flatten \nfrom tensorflow.keras.layers import Add, Concatenate, Lambda, Input, Permute\nfrom tensorflow.keras.regularizers import L2\nimport math\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense\nfrom tensorflow.keras.layers import multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom tensorflow.keras.layers import Dropout, MultiHeadAttention, LayerNormalization, Reshape\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\nfrom tensorflow.keras import layers, regularizers\nfrom tensorflow.keras.constraints import MaxNorm  # Import MaxNorm from the correct module\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.initializers import HeNormal, HeUniform\n\n# Suppress DeprecationWarnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n# Set logging level to suppress INFO and WARNING messages\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  \ntf.get_logger().setLevel('ERROR')  \n\n# Optional: Disable XLA if not needed\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n\nimport random\n# Set random seeds for reproducibility\nseed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nrandom.seed(seed)\n# os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic operations","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:01:45.364947Z","iopub.execute_input":"2024-11-14T20:01:45.365535Z","iopub.status.idle":"2024-11-14T20:01:59.978118Z","shell.execute_reply.started":"2024-11-14T20:01:45.365495Z","shell.execute_reply":"2024-11-14T20:01:59.977096Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess & Data Loader","metadata":{}},{"cell_type":"code","source":"def load_data_LOSO (data_path, subject, dataset): \n    \"\"\" Loading and Dividing of the data set based on the \n    'Leave One Subject Out' (LOSO) evaluation approach. \n    LOSO is used for  Subject-independent evaluation.\n    In LOSO, the model is trained and evaluated by several folds, equal to the \n    number of subjects, and for each fold, one subject is used for evaluation\n    and the others for training. The LOSO evaluation technique ensures that \n    separate subjects (not visible in the training data) are usedto evaluate \n    the model.\n    \n        Parameters\n        ----------\n        data_path: string\n            dataset path\n            # Dataset BCI Competition IV-2a is available at \n            # http://bnci-horizon-2020.eu/database/data-sets\n        subject: int\n            number of subject in [1, .. ,9/14]\n            Here, the subject data is used  test the model and other subjects data\n            for training\n    \"\"\"\n    \n    X_train, y_train = None, None  # Initialize as None for concatenation later\n    X_test, y_test = None, None    # Initialize for the test data\n    \n    for sub in range(0, 9):  # Iterate through subjects (assuming there are 9 subjects)\n        if (dataset == 'BCI2a'):\n            # Directly load the training and testing data without subdirectories\n            X1, y1 = load_BCI2a_data(data_path, sub+1, True)  # Training data\n            X2, y2 = load_BCI2a_data(data_path, sub+1, False) # Test data\n        elif (dataset == 'CS2R'):\n            X1, y1, _, _, _  = load_CS2R_data_v2(data_path, sub, True)\n            X2, y2, _, _, _  = load_CS2R_data_v2(data_path, sub, False)\n\n        # Concatenate training and testing data for each subject\n        X = np.concatenate((X1, X2), axis=0)\n        y = np.concatenate((y1, y2), axis=0)\n                   \n        if sub == subject:\n            # Set aside test data for the current subject\n            X_test = X\n            y_test = y\n        else:\n            # If X_train is None, assign the first subject's data\n            if X_train is None:\n                X_train = X\n                y_train = y\n            else:\n                # Concatenate the current subject's data with previous subjects' data\n                X_train = np.concatenate((X_train, X), axis=0)\n                y_train = np.concatenate((y_train, y), axis=0)\n\n    return X_train, y_train, X_test, y_test\n\ndef load_BCI2a_data(data_path, subject, training, all_trials = True):    \n    # Define MI-trials parameters\n    n_channels = 22\n    n_tests = 6*48     \n    window_Length = 7*250 \n    \n    # Define MI trial window \n    fs = 250          # sampling rate\n    t1 = int(2*fs)  # start time_point\n    t2 = int(6*fs)    # end time_point\n\n    class_return = np.zeros(n_tests)\n    data_return = np.zeros((n_tests, n_channels, window_Length))\n\n    NO_valid_trial = 0\n    if training:\n        a = sio.loadmat(data_path+'A0'+str(subject+1)+'T.mat')\n    else:\n        a = sio.loadmat(data_path+'A0'+str(subject+1)+'E.mat')\n    a_data = a['data']\n    for ii in range(0,a_data.size):\n        a_data1 = a_data[0,ii]\n        a_data2= [a_data1[0,0]]\n        a_data3= a_data2[0]\n        a_X         = a_data3[0]\n        a_trial     = a_data3[1]\n        a_y         = a_data3[2]\n        a_artifacts = a_data3[5]\n\n        for trial in range(0,a_trial.size):\n             if(a_artifacts[trial] != 0 and not all_trials):\n                 continue\n             data_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial]):(int(a_trial[trial])+window_Length),:22])\n             class_return[NO_valid_trial] = int(a_y[trial])\n             NO_valid_trial +=1        \n    \n\n    data_return = data_return[0:NO_valid_trial, :, t1:t2]\n    class_return = class_return[0:NO_valid_trial]\n    class_return = (class_return-1).astype(int)\n\n    return data_return, class_return\n\ndef standardize_data(X_train, X_test, channels): \n    # X_train & X_test :[Trials, MI-tasks, Channels, Time points]\n    for j in range(channels):\n          scaler = StandardScaler()\n          scaler.fit(X_train[:, 0, j, :])\n          X_train[:, 0, j, :] = scaler.transform(X_train[:, 0, j, :])\n          X_test[:, 0, j, :] = scaler.transform(X_test[:, 0, j, :])\n\n    return X_train, X_test\n\ndef batch_cwt(batch_signals, frequencies, sampling_frequency, normalization='zscore'):\n    \"\"\"\n    Compute the Continuous Wavelet Transform (CWT) for a batch of signals using TensorFlow.\n    \n    Args:\n        batch_signals (tf.Tensor): Input batch of signals with shape [batch_size, channels, signal_length].\n        frequencies (np.array): Array of frequencies to use for the CWT.\n        sampling_frequency (int): Sampling frequency of the signals.\n        normalization (str): Type of normalization ('zscore' or 'minmax').\n    \n    Returns:\n        tf.Tensor: Tensor containing the normalized CWT coefficients for the input batch of signals.\n        Shape: (batch_size, frequencies, signal_length, channels)\n    \"\"\"\n    # Extract batch size, channels, and signal length from the tensor\n    batch_size, channels, signal_length = batch_signals.shape\n    \n    # Convert the batch to NumPy at once (avoiding per-signal conversion)\n    batch_signals_np = batch_signals.numpy()\n    \n    # Initialize a list to store the CWT results\n    cwt_batch = []\n    \n    # Loop through the batch to compute CWT for each channel in each sample\n    for i in range(batch_size):\n        cwt_channels = []\n        for ch in range(channels):\n            # Extract the signal for the current channel\n            signal = batch_signals_np[i, ch, :]\n            \n            # Compute CWT for the signal\n            coefficients, _ = pywt.cwt(signal, frequencies, 'cmor1.5-1.0', sampling_period=1/sampling_frequency)\n            coefficients = np.abs(coefficients)  # Take the absolute value of the coefficients\n            \n            # Normalize CWT coefficients based on the chosen method\n            if normalization == 'zscore':\n                # Z-Score normalization: (x - mean) / std\n                mean = np.mean(coefficients)\n                std = np.std(coefficients)\n                coefficients = (coefficients - mean) / std if std != 0 else coefficients\n            elif normalization == 'minmax':\n                # Min-Max normalization: (x - min) / (max - min)\n                min_val = np.min(coefficients)\n                max_val = np.max(coefficients)\n                coefficients = (coefficients - min_val) / (max_val - min_val) if max_val != min_val else coefficients\n            \n            # Append normalized CWT coefficients for the current channel\n            cwt_channels.append(coefficients)\n        \n        # Stack CWT results for all channels of the current sample\n        cwt_channels_stacked = np.stack(cwt_channels, axis=0)  # Shape: (channels, frequencies, signal_length)\n        cwt_batch.append(cwt_channels_stacked)\n    \n    # Convert the list of CWT results into a single tensor\n    cwt_batch_np = np.array(cwt_batch)  # Shape: (batch_size, channels, frequencies, signal_length)\n    \n    # Transpose dimensions to match image format\n    cwt_batch_np = np.transpose(cwt_batch_np, (0, 2, 3, 1))  # Shape: (batch_size, frequencies, signal_length, channels)\n    \n    # Convert the normalized CWT batch back to a TensorFlow tensor\n    cwt_batch_tensor = tf.convert_to_tensor(cwt_batch_np, dtype=tf.float32)\n\n    return cwt_batch_tensor\n\ndef get_data(path, subject, frequencies, sampling_frequency, dataset='BCI2a', classes_labels='all', LOSO=False, \n             isStandard=True, isShuffle=True, include_cwt=True):\n    \n    # Load and split the dataset into training and testing\n    if LOSO:\n        X_train, y_train, X_test, y_test = load_data_LOSO(path, subject, dataset)\n    else:\n        if dataset == 'BCI2a':\n            X_train, y_train = load_BCI2a_data(path, subject, True)\n            X_test, y_test = load_BCI2a_data(path, subject, False)\n\n    # Shuffle the data if specified\n    if isShuffle:\n        X_train, y_train = shuffle(X_train, y_train, random_state=seed)\n        X_test, y_test = shuffle(X_test, y_test, random_state=seed)\n\n    # Reshape the training data\n    N_tr, N_ch, T = X_train.shape\n    X_train = X_train.reshape(N_tr, 1, N_ch, T)\n    y_train_onehot = to_categorical(y_train)\n\n    # Reshape the testing data\n    N_te, N_ch, T = X_test.shape\n    X_test = X_test.reshape(N_te, 1, N_ch, T)\n    y_test_onehot = to_categorical(y_test)\n\n    # Standardize the data if specified\n    if isStandard:\n        X_train, X_test = standardize_data(X_train, X_test, N_ch)\n\n    # Ensure shape consistency\n    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n    print(f\"y_train_onehot shape: {y_train_onehot.shape}, y_test_onehot shape: {y_test_onehot.shape}\")\n\n    # Transpose the data\n    X_train_transposed = tf.transpose(X_train, perm=[0, 2, 1, 3])  # (288, 22, 1, 1125)\n    X_test_transposed = tf.transpose(X_test, perm=[0, 2, 1, 3])    # (288, 22, 1, 1125)\n\n    # Squeeze only the singleton dimension (the last dimension, which is size 1)\n    X_train_squeezed = tf.squeeze(X_train_transposed, axis=2)  # Shape: (288, 22, 1125)\n    X_test_squeezed = tf.squeeze(X_test_transposed, axis=2)    # Shape: (288, 22, 1125)\n\n    # Apply the batch_cwt function for both training and test data\n    X_train_cwt = batch_cwt(X_train_squeezed, frequencies, sampling_frequency)\n    X_test_cwt = batch_cwt(X_test_squeezed, frequencies, sampling_frequency)\n\n    # Ensure shape consistency after CWT\n    print(f\"X_train_cwt shape: {X_train_cwt.shape}, X_test_cwt shape: {X_test_cwt.shape}\")\n\n    # Return CWT data and labels\n    return X_train, y_train, y_train_onehot, X_test, y_test, y_test_onehot, X_train_cwt, X_test_cwt","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:01:59.980089Z","iopub.execute_input":"2024-11-14T20:01:59.980642Z","iopub.status.idle":"2024-11-14T20:02:00.014432Z","shell.execute_reply.started":"2024-11-14T20:01:59.980576Z","shell.execute_reply":"2024-11-14T20:02:00.013360Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"def add_noise(data, noise_factor=0.001, seed=42):\n    \"\"\"Add Gaussian noise to the data.\"\"\"\n    return data + noise_factor * tf.random.normal(shape=tf.shape(data), dtype=tf.float32, seed=seed)\n\ndef scale_data(data, min_scale=0.9, max_scale=1.1, seed=42):\n    \"\"\"Scale the data by a random factor.\"\"\"\n    scale = tf.random.uniform([], minval=min_scale, maxval=max_scale, dtype=tf.float32, seed=seed)\n    return data * scale\n\ndef apply_time_mask(data, max_mask_size=10, seed=42):\n    \"\"\"Apply a random time mask to the data.\"\"\"\n    time_steps = tf.shape(data)[1]\n    time_mask_start = tf.random.uniform([], minval=0, maxval=time_steps, dtype=tf.int32, seed=seed)\n    mask_size = tf.random.uniform([], minval=0, maxval=tf.minimum(max_mask_size, time_steps - time_mask_start), dtype=tf.int32, seed=seed)\n\n    mask = tf.ones(shape=[tf.shape(data)[0], mask_size, tf.shape(data)[2]])\n    mask = tf.pad(mask, [[0, 0], [time_mask_start, time_steps - time_mask_start - mask_size], [0, 0]], \"CONSTANT\")\n    mask = tf.expand_dims(mask, axis=-1)\n\n    return data * (1.0 - mask)\n\ndef mixup_augmentation(cwt_data, labels, alpha=0.2, seed=42):\n    \"\"\"Apply mixup augmentation to CWT data.\"\"\"\n    num_samples = tf.shape(cwt_data)[0]\n    tf.random.set_seed(seed)\n\n    # Choose random indices for mixup\n    random_indices = tf.random.shuffle(tf.range(num_samples), seed=seed)\n    mixup_lambda = tf.random.uniform([num_samples, 1, 1, 1], minval=0, maxval=alpha, dtype=tf.float32, seed=seed)\n\n    # Ensure labels are broadcast-compatible and of type float32\n    if len(labels.shape) == 2:  # Assuming [num_samples, num_classes]\n        mixup_lambda_labels = tf.reshape(mixup_lambda, [num_samples, 1])\n\n    # Convert labels to float32 if needed\n    labels = tf.cast(labels, tf.float32)\n    mixup_lambda_labels = tf.cast(mixup_lambda_labels, tf.float32)\n\n    # Mix data and labels with chosen lambda\n    mixed_data = mixup_lambda * cwt_data + (1 - mixup_lambda) * tf.gather(cwt_data, random_indices)\n    mixed_labels = mixup_lambda_labels * labels + (1 - mixup_lambda_labels) * tf.gather(labels, random_indices)\n    \n    return mixed_data, mixed_labels\n\ndef augment_time_domain(timg, label, seed=42):\n    \"\"\"Apply multiple combinations of augmentations on time-domain data.\"\"\"\n    tf.random.set_seed(seed)\n\n    # Apply all augmentations in batch\n    noise_data = add_noise(timg, seed=seed)\n    scale_data_only = scale_data(timg, seed=seed)\n    noise_scale_data = scale_data(noise_data, seed=seed)\n    noise_scale_mask_data = apply_time_mask(noise_scale_data, seed=seed)\n\n    # Concatenate once for efficiency\n    X_time_aug_combined = tf.concat([timg, noise_data, scale_data_only, noise_scale_data, noise_scale_mask_data], axis=0)\n    y_time_aug_combined = tf.tile(label, [5, 1])\n\n    return X_time_aug_combined, y_time_aug_combined\n\ndef shift_data(cwt_data, shift_range=(-3, 4), seed=42):\n    \"\"\"Shift the CWT data along the time dimension.\"\"\"\n    batch_size, freqs, time_steps, channels = tf.shape(cwt_data)\n    shift = tf.random.uniform([], minval=shift_range[0], maxval=shift_range[1], dtype=tf.int32, seed=seed)\n\n    if shift > 0:\n        shifted = tf.concat([tf.zeros([batch_size, freqs, shift, channels]), cwt_data[:, :, :-shift, :]], axis=2)\n    elif shift < 0:\n        shifted = tf.concat([cwt_data[:, :, -shift:, :], tf.zeros([batch_size, freqs, -shift, channels])], axis=2)\n    else:\n        shifted = cwt_data\n\n    return shifted\n\ndef augment_cwt(cwt_data, label, seed=42):\n    \"\"\"Apply multiple combinations of augmentations on CWT data.\"\"\"\n    tf.random.set_seed(seed)\n\n    noise_cwt = add_noise(cwt_data, seed=seed)\n    shift_cwt = shift_data(cwt_data, seed=seed)\n    noise_shift_cwt = shift_data(noise_cwt, seed=seed)\n    mixup_noise_shift_cwt, mixup_labels = mixup_augmentation(noise_shift_cwt, label, seed=seed)\n\n    X_cwt_aug_combined = tf.concat([cwt_data, noise_cwt, shift_cwt, noise_shift_cwt, mixup_noise_shift_cwt], axis=0)\n    y_cwt_aug_combined = tf.concat([label] * 4 + [mixup_labels], axis=0)\n\n    return X_cwt_aug_combined, y_cwt_aug_combined\n\ndef time_and_cwt_augment(timg, cwt_data, label, seed=42):\n    \"\"\"Apply both time-domain and CWT augmentations.\"\"\"\n    X_time_aug_combined, y_time_aug_combined = augment_time_domain(timg, label, seed=seed)\n    X_cwt_aug_combined, y_cwt_aug_combined = augment_cwt(cwt_data, label, seed=seed)\n\n    return X_time_aug_combined, X_cwt_aug_combined, y_time_aug_combined","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:00.016182Z","iopub.execute_input":"2024-11-14T20:02:00.016566Z","iopub.status.idle":"2024-11-14T20:02:00.056801Z","shell.execute_reply.started":"2024-11-14T20:02:00.016521Z","shell.execute_reply":"2024-11-14T20:02:00.055871Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Attention Blocks","metadata":{}},{"cell_type":"code","source":"!pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:00.058993Z","iopub.execute_input":"2024-11-14T20:02:00.059325Z","iopub.status.idle":"2024-11-14T20:02:12.763856Z","shell.execute_reply.started":"2024-11-14T20:02:00.059277Z","shell.execute_reply":"2024-11-14T20:02:12.762644Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class TS_AttentionModule(layers.Layer):\n    def __init__(self, emb_size, num_heads, dropout):\n        super(TS_AttentionModule, self).__init__()\n        self.emb_size = emb_size\n        self.num_heads = num_heads\n        self.dropout = dropout\n        \n        # Linear layers for queries, keys, and values\n        self.query_dense = layers.Dense(emb_size)\n        self.key_dense = layers.Dense(emb_size)\n        self.value_dense = layers.Dense(emb_size)\n        self.dropout_layer = layers.Dropout(dropout)\n        \n        # Linear projection after attention output\n        self.projection = layers.Dense(emb_size)\n\n    def call(self, query, key, value, mask=None):\n        # Dense layers for queries, keys, and values\n        queries = self.query_dense(query)\n        keys = self.key_dense(key)\n        values = self.value_dense(value)\n        \n        # Reshape for multi-head attention\n        batch_size = tf.shape(queries)[0]\n        seq_len = tf.shape(queries)[1]\n        head_dim = self.emb_size // self.num_heads\n        \n        # Reshaping queries, keys, and values for multiple heads\n        queries = tf.reshape(queries, (batch_size, seq_len, self.num_heads, head_dim))\n        keys = tf.reshape(keys, (batch_size, seq_len, self.num_heads, head_dim))\n        values = tf.reshape(values, (batch_size, seq_len, self.num_heads, head_dim))\n\n        # Transpose to prepare for scaled dot-product attention\n        queries = tf.transpose(queries, perm=[0, 2, 1, 3])\n        keys = tf.transpose(keys, perm=[0, 2, 1, 3])\n        values = tf.transpose(values, perm=[0, 2, 1, 3])\n        \n        # Scaled dot-product attention\n        attention_scores = tf.matmul(queries, keys, transpose_b=True) # energy\n        attention_scores = attention_scores / tf.math.sqrt(tf.cast(head_dim, tf.float32))\n        \n        if mask is not None:\n            attention_scores += (mask * -1e9)\n        \n        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n        attention_weights = self.dropout_layer(attention_weights)\n        \n        # Calculate attention output\n        attention_output = tf.matmul(attention_weights, values)\n        \n        # Transpose and reshape back to original form\n        attention_output = tf.transpose(attention_output, perm=[0, 2, 1, 3])\n        attention_output = tf.reshape(attention_output, (batch_size, seq_len, self.emb_size))\n        \n        # Final projection to combine heads\n        output = self.projection(attention_output)\n        \n        return output\n\ndef TS_ResidualAdd(x, fn):\n    \"\"\"\n    Residual connection followed by function application.\n    \n    Parameters:\n        x (tf.Tensor): Input tensor.\n        fn (function): A function to apply to the input tensor.\n        \n    Returns:\n        tf.Tensor: Output tensor after residual connection and function application.\n    \"\"\"\n    res = x\n    x = fn(x)\n    return res + x\n\ndef TS_FeedForwardBlock(x, emb_size, expansion, drop_p):\n    \"\"\"\n    Feed-forward block with linear layers.\n    \n    Args:\n        x (tf.Tensor): Input tensor.\n        emb_size (int): Embedding size.\n        expansion (int): Expansion factor for the feed-forward layer.\n        drop_p (float): Dropout probability.\n    \n    Returns:\n        tf.Tensor: Output tensor after feed-forward processing.\n    \"\"\"\n    # First dense layer with expansion\n    x = layers.Dense(expansion * emb_size)(x)\n    \n    # GELU activation wrapped in a Keras layer\n    x = layers.Activation('gelu')(x)\n    \n    # Dropout wrapped in a Keras layer\n    x = layers.Dropout(drop_p)(x)\n    \n    # Second dense layer to map back to embedding size\n    x = layers.Dense(emb_size)(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.765536Z","iopub.execute_input":"2024-11-14T20:02:12.765968Z","iopub.status.idle":"2024-11-14T20:02:12.783199Z","shell.execute_reply.started":"2024-11-14T20:02:12.765919Z","shell.execute_reply":"2024-11-14T20:02:12.782157Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Main Attention Block","metadata":{}},{"cell_type":"code","source":"from einops import rearrange\n\ndef attention_block(in_layer, freq_features, emb_size=32, num_heads=4, dropout=0.3, ratio=8, \n                    residual=True, apply_to_input=True, forward_expansion=4, forward_drop_p=0.5, \n                    **kwargs):\n    \n    # Positional encoding initialization (can be trainable or fixed)\n    seq_len = in_layer.shape[1]\n    pos_embedding_in = layers.Embedding(input_dim=seq_len, output_dim=emb_size)\n    pos_embedding_freq = layers.Embedding(input_dim=freq_features.shape[1], output_dim=emb_size)\n    \n    # Step 1: Layer normalization for stability\n    layer_norm = layers.LayerNormalization(epsilon=1e-6)\n    in_layer_norm = layer_norm(in_layer)\n    freq_features_norm = layer_norm(freq_features)\n\n    # Step 2: Add positional encoding to both time-series and frequency features\n    pos_indices_in = tf.range(start=0, limit=seq_len, delta=1)\n    pos_indices_freq = tf.range(start=0, limit=freq_features.shape[1], delta=1)\n\n    in_layer_pos_encoded = in_layer_norm + pos_embedding_in(pos_indices_in)\n    freq_features_pos_encoded = freq_features_norm + pos_embedding_freq(pos_indices_freq)\n\n    # Step 3: Project and Reshape Frequency Features before Cross-Attention\n    freq_features_projected = layers.Dense(in_layer.shape[1])(freq_features_pos_encoded)\n    freq_features_norm = layers.LayerNormalization(epsilon=1e-6)(freq_features_projected)\n    freq_features_norm = layers.Reshape((in_layer.shape[1], -1))(freq_features_norm)\n\n    # Step 4: Use TS_AttentionModule for Cross-Attention with freq_features_norm as key and value\n    cross_attention_output = TS_AttentionModule(emb_size, num_heads, dropout)(\n        query=in_layer_pos_encoded, key=freq_features_norm, value=in_layer_pos_encoded)\n\n    # Step 5: Residual Connection after Cross-Attention using TS_ResidualAdd\n    if residual:\n        cross_attention_output = TS_ResidualAdd(\n            in_layer_pos_encoded, lambda x: TS_AttentionModule(emb_size, num_heads, dropout)(\n                x, key=freq_features_norm, value=in_layer_pos_encoded))\n\n    # Step 6: Apply the Feedforward Block using TS_FeedForwardBlock\n    feedforward_output = TS_FeedForwardBlock(cross_attention_output, emb_size, forward_expansion, forward_drop_p)\n\n    # Step 7: Final residual connection (optional)\n    if residual:\n        final_output = TS_ResidualAdd(cross_attention_output, lambda x: TS_FeedForwardBlock(x, emb_size, forward_expansion, forward_drop_p))\n    else:\n        final_output = feedforward_output\n\n    return final_output","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.784471Z","iopub.execute_input":"2024-11-14T20:02:12.784768Z","iopub.status.idle":"2024-11-14T20:02:12.803586Z","shell.execute_reply.started":"2024-11-14T20:02:12.784736Z","shell.execute_reply":"2024-11-14T20:02:12.802770Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Time Frequency Conv","metadata":{}},{"cell_type":"code","source":"# Custom layer for squeezing\nclass SqueezeLayer(Layer):\n    def __init__(self, axis):\n        super(SqueezeLayer, self).__init__()\n        self.axis = axis\n\n    def call(self, inputs):\n        return tf.squeeze(inputs, axis=self.axis)\n    \nclass TransposeLayer(layers.Layer):\n    def call(self, x):\n        return tf.transpose(x, perm=[0, 1, 3, 2])  # Transpose to (batch_size, frequencies, channels, time)\n\ndef tf_conv_module(x, output_features=32, target_seq_len=None):\n    \"\"\"\n    Modified Conv Module to produce features suitable for Key/Value in MultiHeadAttention.\n    \n    Parameters:\n    - x: Input tensor (batch_size, frequencies, samples, channels)\n    - output_features: Number of output features to match the query in MHA.\n    - target_seq_len: The desired sequence length to match the query for MHA. If None, uses the frequency dimension size.\n    \n    Returns:\n    - block1: Processed tensor ready for use as Key/Value in MultiHeadAttention.\n    \"\"\"\n    weightDecay = 0.009\n    maxNormValue = 0.6  # MaxNorm constraint value\n\n    # Step 1: Transpose Layer to align channels (from input shape to (batch_size, frequencies, channels, time))\n    x = TransposeLayer()(x)  # Output shape: (batch_size, frequencies, channels, time)\n#     print(\"After TransposeLayer:\", x.shape)\n\n    # Step 2: First Conv2D Layer (Capture frequency-time patterns)\n    x = layers.SeparableConv2D(16, (1, 10), padding='same', \n                           depthwise_regularizer=regularizers.l2(weightDecay),\n                           pointwise_regularizer=regularizers.l2(weightDecay),\n                           activation=None)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ELU()(x)\n#     print(\"After first Conv2D:\", x.shape)\n\n    # Step 3: Depthwise Conv2D Layer (Better capture of frequency patterns across channels)\n    x = layers.DepthwiseConv2D(kernel_size=(1, 22), padding='same', \n                               depthwise_regularizer=regularizers.l2(weightDecay),\n                               depthwise_constraint=MaxNorm(maxNormValue))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ELU()(x)\n#     print(\"After DepthwiseConv2D:\", x.shape)\n    \n    # Step 4: Dropout for regularization\n    x = layers.Dropout(0.5)(x)\n\n    # Step 5: Pointwise Conv2D Layer (Increase feature complexity)\n    x = layers.Conv2D(32, kernel_size=(1, 1), padding='same', \n                      kernel_regularizer=regularizers.l2(weightDecay),\n                      kernel_constraint=MaxNorm(maxNormValue), activation=None)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ELU()(x)\n#     print(\"After Pointwise Conv2D:\", x.shape)\n\n    # Step 6: Second Conv2D Layer (Enhanced features across frequencies)\n    x = layers.Conv2D(32, (4, 1), padding='same', \n                      kernel_regularizer=regularizers.l2(weightDecay),\n                      kernel_constraint=MaxNorm(maxNormValue), activation=None)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ELU()(x)\n#     print(\"After second Conv2D:\", x.shape)\n\n    x = layers.AveragePooling2D(pool_size=(1, 18))(x)\n    # print(\"After first AveragePooling2D:\", x.shape)\n\n    # Step 8: Dropout Layer for regularization\n    x = layers.Dropout(0.6)(x)\n\n    # Step 9: Final Conv Layer to reduce features to `output_features` (32)\n    x = layers.Conv2D(output_features, (1, 1), padding='same', \n                      kernel_regularizer=regularizers.l2(weightDecay),\n                      kernel_constraint=MaxNorm(maxNormValue), activation=None)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ELU()(x)\n#     print(\"After final Conv2D (output features):\", x.shape)\n\n    x = SqueezeLayer(axis=2)(x)\n#     print(\"After Squeze:\", x.shape)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.804679Z","iopub.execute_input":"2024-11-14T20:02:12.805046Z","iopub.status.idle":"2024-11-14T20:02:12.821764Z","shell.execute_reply.started":"2024-11-14T20:02:12.805013Z","shell.execute_reply":"2024-11-14T20:02:12.820856Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Time Series Conv","metadata":{}},{"cell_type":"code","source":"def TS_Conv_block(input_layer, F1=4, kernLength=64, poolSize=7, D=2, in_chans=22, \n                  weightDecay=0.01, maxNorm=0.6, dropout=0.3):\n    \"\"\" Conv_block with moderate kernel size variations and feature averaging using `layers`. \"\"\"\n\n    F2 = F1 * D\n    \n    # Block 1a: First Convolution with kernLength = 32\n    block1a = layers.Conv2D(F1, (kernLength, 1), padding='same', data_format='channels_last', \n                            kernel_regularizer=regularizers.L2(weightDecay),\n                            kernel_constraint=max_norm(maxNorm, axis=[0, 1, 2]), use_bias=False)(input_layer)\n    block1a = layers.BatchNormalization(axis=-1)(block1a)\n\n    # Block 1b: Convolution with kernLength + 16 = 48\n    block1b = layers.Conv2D(F1, (kernLength + 16, 1), padding='same', data_format='channels_last', \n                            kernel_regularizer=regularizers.L2(weightDecay),\n                            kernel_constraint=max_norm(maxNorm, axis=[0, 1, 2]), use_bias=False)(input_layer)\n    block1b = layers.BatchNormalization(axis=-1)(block1b)\n\n    # Block 1c: Convolution with kernLength - 16 = 16\n    block1c = layers.Conv2D(F1, (kernLength - 16, 1), padding='same', data_format='channels_last', \n                            kernel_regularizer=regularizers.L2(weightDecay),\n                            kernel_constraint=max_norm(maxNorm, axis=[0, 1, 2]), use_bias=False)(input_layer)\n    block1c = layers.BatchNormalization(axis=-1)(block1c)\n\n    # Averaging the outputs from different kernel sizes\n    block1 = layers.Average()([block1a, block1b, block1c])\n\n    # Block 2: Depthwise Convolution\n    block2 = layers.DepthwiseConv2D((1, in_chans), depth_multiplier=D, data_format='channels_last',\n                                    depthwise_regularizer=regularizers.L2(weightDecay),\n                                    depthwise_constraint=max_norm(maxNorm, axis=[0, 1, 2]), use_bias=False)(block1)\n    block2 = layers.BatchNormalization(axis=-1)(block2)\n    block2 = layers.Activation('elu')(block2)\n    \n    # Adjusted Pooling to retain more spatial information\n    block2 = layers.AveragePooling2D((6, 1), data_format='channels_last')(block2)  # Reduce pooling size to (6,1)\n    block2 = layers.Dropout(dropout)(block2)\n    \n    # Block 3: Final Convolution\n    block3 = layers.Conv2D(F2, (16, 1), padding='same', data_format='channels_last',\n                           kernel_regularizer=regularizers.L2(weightDecay),\n                           kernel_constraint=max_norm(maxNorm, axis=[0, 1, 2]), use_bias=False)(block2)\n    block3 = layers.BatchNormalization(axis=-1)(block3)\n    block3 = layers.Activation('elu')(block3)\n    \n    # Final Pooling\n    block3 = layers.AveragePooling2D((7, 1), data_format='channels_last')(block3)\n    block3 = layers.Dropout(dropout)(block3)\n    \n    return block3","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.823126Z","iopub.execute_input":"2024-11-14T20:02:12.823451Z","iopub.status.idle":"2024-11-14T20:02:12.838006Z","shell.execute_reply.started":"2024-11-14T20:02:12.823419Z","shell.execute_reply":"2024-11-14T20:02:12.837105Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Temporal Convolution Block","metadata":{}},{"cell_type":"code","source":"class GatedLinearUnit(Layer):\n    def __init__(self, **kwargs):\n        super(GatedLinearUnit, self).__init__(**kwargs)\n    \n    def call(self, x):\n        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)  # Split into two equal parts\n        return x1 * tf.sigmoid(x2)  # Apply gating\n\ndef TCN_block(input_layer, input_dimension, depth, kernel_size, filters, dropout, \n               weightDecay=0.009, maxNorm=0.6):\n    \"\"\" TCN block with GLU and optimized dropout \"\"\"\n    \n    # Initial Conv1D block with GLU\n    block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=1, activation='linear',\n                   kernel_regularizer=L2(weightDecay),\n                   kernel_constraint=max_norm(maxNorm, axis=[0, 1]),\n                   padding='causal', kernel_initializer='he_uniform')(input_layer)\n    block = BatchNormalization()(block)\n    block = SpatialDropout1D(dropout)(block)\n    \n    block = GatedLinearUnit()(block)  # Apply GLU as a layer\n\n    # Second Conv1D block with GLU\n    block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=1, activation='linear',\n                   kernel_regularizer=L2(weightDecay),\n                   kernel_constraint=max_norm(maxNorm, axis=[0, 1]),\n                   padding='causal', kernel_initializer='he_uniform')(block)\n    block = BatchNormalization()(block)\n    block = SpatialDropout1D(dropout)(block)\n\n    # Residual connection\n    if input_dimension != filters:\n        conv = Conv1D(filters, kernel_size=1, activation='linear',\n                      kernel_regularizer=L2(weightDecay),\n                      kernel_constraint=max_norm(maxNorm, axis=[0, 1]),\n                      padding='same')(input_layer)\n        conv = BatchNormalization()(conv)\n        conv = GatedLinearUnit()(conv)  # Apply GLU to residual connection\n        added = Add()([block, conv])\n    else:\n        added = Add()([block, input_layer])\n    \n    out = Activation('linear')(added)  # Maintain the linearity after residual addition\n\n    # Repeat for additional depth\n    for i in range(depth - 1):\n        block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=2**(i + 1), activation='linear',\n                       kernel_regularizer=L2(weightDecay),\n                       kernel_constraint=max_norm(maxNorm, axis=[0, 1]),\n                       padding='causal', kernel_initializer='he_uniform')(out)\n        block = BatchNormalization()(block)\n        block = SpatialDropout1D(dropout)(block)\n        \n        block = GatedLinearUnit()(block)  # Apply GLU\n\n        block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=2**(i + 1), activation='linear',\n                       kernel_regularizer=L2(weightDecay),\n                       kernel_constraint=max_norm(maxNorm, axis=[0, 1]),\n                       padding='causal', kernel_initializer='he_uniform')(block)\n        block = BatchNormalization()(block)\n        block = SpatialDropout1D(dropout)(block)\n\n        # Add residual connection\n        added = Add()([block, out])\n        out = Activation('linear')(added)  # Keep it linear for residual\n        \n    return out","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.839599Z","iopub.execute_input":"2024-11-14T20:02:12.840027Z","iopub.status.idle":"2024-11-14T20:02:12.855998Z","shell.execute_reply.started":"2024-11-14T20:02:12.839985Z","shell.execute_reply":"2024-11-14T20:02:12.855169Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Our Model","metadata":{}},{"cell_type":"code","source":"#%% The proposed model, \ndef TSxTF(n_classes, frequencies, in_chans=22, in_samples=1125, eegn_F1=16, \n            eegn_D=2, eegn_kernelSize=64, eegn_poolSize=7, eegn_dropout=0.3,\n            tcn_depth=1, tcn_kernelSize=4, tcn_filters=32, tcn_dropout=0.3,\n            tcn_activation='elu', fuse='average'):\n\n    # Time-series Input\n    input_eeg = Input(shape=(1, in_chans, in_samples))  # (batch_size, 1, channels, samples)\n    \n    # Frequency-series Input\n    input_freq = Input(shape=(len(frequencies), in_samples, in_chans))  # (batch_size, frequencies, samples, channels)\n\n    dense_weightDecay = 0.5\n    conv_weightDecay = 0.009\n    conv_maxNorm = 0.6\n    from_logits = False\n\n    numFilters = eegn_F1\n    F2 = numFilters * eegn_D\n\n    # EEG Convolution Block for Time-Series Input\n    input_eeg_permuted = Permute((3, 2, 1))(input_eeg)  # (batch_size, samples, channels, 1)\n    block1 = TS_Conv_block(input_layer=input_eeg_permuted, F1=eegn_F1, D=eegn_D,\n                         kernLength=eegn_kernelSize, poolSize=eegn_poolSize,\n                         weightDecay=conv_weightDecay, maxNorm=conv_maxNorm,\n                         in_chans=in_chans, dropout=eegn_dropout)\n\n    block1 = Lambda(lambda x: x[:, :, -1, :])(block1)  # Squeeze sequence dimension if needed\n\n    # Frequency Features for Attention Mask using TF_ConvModule\n    freq_features = tf_conv_module(input_freq)  # Extract features from frequency input\n\n    # Apply a 1D Convolution to the entire time series\n    conv_layer = Conv1D(filters=tcn_filters, kernel_size=3, padding='same')(block1)  # Temporal convolution(SW complement)\n\n    attention_layer = attention_block(conv_layer, freq_features=freq_features)\n\n    # Temporal Convolutional Network (TCN)\n    tcn_output = TCN_block(input_layer=attention_layer, input_dimension=F2, depth=tcn_depth,\n                            kernel_size=tcn_kernelSize, filters=tcn_filters,\n                            weightDecay=conv_weightDecay, maxNorm=conv_maxNorm,\n                            dropout=tcn_dropout)\n\n    # Global Average Pooling to capture information over the entire sequence\n    global_avg_pool = GlobalAveragePooling1D()(tcn_output)\n\n    # Final Dense Layer for classification\n    final_dense = Dense(n_classes, kernel_regularizer=L2(dense_weightDecay))(global_avg_pool)\n\n    # Final output layer (softmax or linear)\n    if from_logits:\n        out = Activation('linear', name='linear')(final_dense)\n    else:\n        out = Activation('softmax', name='softmax')(final_dense)\n\n    # Create the model with EEG and CWT inputs\n    return Model(inputs=[input_eeg, input_freq], outputs=out)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.858811Z","iopub.execute_input":"2024-11-14T20:02:12.859184Z","iopub.status.idle":"2024-11-14T20:02:12.871272Z","shell.execute_reply.started":"2024-11-14T20:02:12.859146Z","shell.execute_reply":"2024-11-14T20:02:12.870505Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Train_Test","metadata":{}},{"cell_type":"code","source":"pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:12.872349Z","iopub.execute_input":"2024-11-14T20:02:12.872736Z","iopub.status.idle":"2024-11-14T20:02:24.392484Z","shell.execute_reply.started":"2024-11-14T20:02:12.872692Z","shell.execute_reply":"2024-11-14T20:02:24.391348Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomTQDMProgressBar(Callback):\n    def on_train_begin(self, logs=None):\n        # Initialize the tqdm progress bar for epochs\n        self.epochs_bar = tqdm(total=self.params['epochs'], position=0, desc='Epochs', unit='epoch')\n        # Initialize variables to track best validation accuracy and loss, and their corresponding epochs\n        self.best_val_acc = 0.0\n        self.best_epoch_acc = 0\n        self.best_val_loss = float('inf')  # Start with infinity for minimum comparison\n        self.best_epoch_loss = 0\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Retrieve relevant metrics from logs\n        train_acc = logs.get('accuracy', 0.0)\n        val_acc = logs.get('val_accuracy', 0.0)\n        val_loss = logs.get('val_loss', float('inf'))  # Default to infinity if not available\n\n        # Update the best validation accuracy and epoch if the current accuracy is higher\n        if val_acc > self.best_val_acc:\n            self.best_val_acc = val_acc\n            self.best_epoch_acc = epoch + 1  # Store the best epoch (1-based index)\n\n        # Update the best validation loss and epoch if the current loss is lower\n        if val_loss < self.best_val_loss:\n            self.best_val_loss = val_loss\n            self.best_epoch_loss = epoch + 1  # Store the best epoch (1-based index)\n\n        # Update the progress bar description with metrics, including best validation accuracy and loss\n        self.epochs_bar.set_description(\n            f\"Epoch {epoch + 1}, Train Acc: {train_acc:.4f}, Valid Acc: {val_acc:.4f}, Valid Loss: {val_loss:.4f}, \"\n            f\"Best Valid Acc: {self.best_val_acc:.4f} (Epoch {self.best_epoch_acc}), \"\n            f\"Best Valid Loss: {self.best_val_loss:.4f} (Epoch {self.best_epoch_loss})\"\n        )\n\n        # Move the progress bar by 1 epoch\n        self.epochs_bar.update(1)\n\n    def on_train_end(self, logs=None):\n        # Close the tqdm progress bar at the end of training\n        self.epochs_bar.close()\n\n#%%\ndef draw_learning_curves(history, sub):\n    # Plot training and validation accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy - subject: ' + str(sub))\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='center right')\n    plt.show()\n    # Plot training and validation loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss - subject: ' + str(sub))\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='center right')\n    plt.show()\n    # Plot validation accuracy and loss together on the same plot with dual y-axes\n    fig, ax1 = plt.subplots()\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Validation Loss', color='tab:blue')\n    ax1.plot(history.history['val_loss'], color='tab:blue', label='Validation Loss')\n    ax1.tick_params(axis='y', labelcolor='tab:blue')\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    ax2.set_ylabel('Validation Accuracy', color='tab:red')\n    ax2.plot(history.history['val_accuracy'], color='tab:red', label='Validation Accuracy')\n    ax2.tick_params(axis='y', labelcolor='tab:red')\n    fig.suptitle('Validation Accuracy and Loss - subject: ' + str(sub))\n    fig.tight_layout()  # adjust layout to make room for both y-axes\n    plt.show()\n    # Close the plot to avoid memory issues\n    plt.close()\n\ndef draw_confusion_matrix(cf_matrix, sub, results_path, classes_labels):\n    # Generate confusion matrix plot\n    display_labels = classes_labels\n    disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n                                display_labels=display_labels)\n    disp.plot()\n    disp.ax_.set_xticklabels(display_labels, rotation=12)\n    plt.title('Confusion Matrix of Subject: ' + sub )\n    plt.savefig(results_path + '/subject_' + sub + '.png')\n    plt.show()\n\ndef draw_performance_barChart(num_sub, metric, label, mean_best_value):\n    fig, ax = plt.subplots()\n    x = list(range(1, num_sub + 1))\n    # Draw the bar chart for each subject's metric\n    bars = ax.bar(x, metric, 0.5, label=label) \n    # Draw a dotted line for the overall mean of the best scores\n    ax.axhline(y=mean_best_value, color='r', linestyle='--', label=f'Avg {label} ({mean_best_value:.4f})')\n    # Add labels and titles\n    ax.set_ylabel(label)\n    ax.set_xlabel(\"Subject\")\n    ax.set_xticks(x)\n    ax.set_title(f'Model {label} per Subject')\n    ax.set_ylim([0, 1])\n    ax.legend(loc='upper right')\n    # Display the accuracy score above each bar\n    for bar, score in zip(bars, metric):\n        ax.text(\n            bar.get_x() + bar.get_width() / 2,  # X-coordinate\n            bar.get_height(),                  # Y-coordinate (top of the bar)\n            f'{score:.4f}',                    # Text (formatted score)\n            ha='center', va='bottom'           # Center text horizontally, below text vertically\n        )  \n    # Show the plot\n    plt.show()\n    \ndef plot_tsne(features, labels, title=\"t-SNE Plot\", class_labels=['Left hand', 'Right hand', 'Foot', 'Tongue'],\n              perplexity=40, learning_rate=100, n_pca_components=30, save_path='./tsne_plot.png'):\n    # Reduce dimensions with PCA before applying t-SNE\n#     pca = PCA(n_components=n_pca_components, random_state=42)\n#     pca_results = pca.fit_transform(features)\n    # Apply t-SNE\n    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, init='pca', random_state=42)\n#     tsne = TSNE(n_components=2, perplexity=perplexity,init='pca', random_state=166)\n#     tsne_results = tsne.fit_transform(pca_results)\n    tsne_results = tsne.fit_transform(features)\n    # Normalize t-SNE results for consistent plotting\n    x_min, x_max = tsne_results.min(0), tsne_results.max(0)\n    tsne_normalized = (tsne_results - x_min) / (x_max - x_min)\n    # Define specific colors for each class\n    colors = ['red', 'blue', 'green', 'brown']\n    # Create the scatter plot\n    plt.figure(figsize=(8, 6))\n    for i, label in enumerate(np.unique(labels)):\n        # Select data points belonging to the current class\n        class_points = tsne_normalized[labels == label]\n        plt.scatter(class_points[:, 0], class_points[:, 1], \n                    color=colors[i], label=class_labels[label], alpha=0.7)\n    # Add plot details\n    plt.title(title)\n    plt.xlabel(\"t-SNE Component 1\")\n    plt.ylabel(\"t-SNE Component 2\")\n    plt.xticks([])  # Remove x-axis ticks for cleaner visualization\n    plt.yticks([])  # Remove y-axis ticks for cleaner visualization\n    plt.legend()\n    plt.show()\n\ndef train_and_test(dataset_conf, train_conf, results_path):\n    # Remove the 'results' folder before training\n    if os.path.exists(results_path):\n        shutil.rmtree(results_path)\n    os.makedirs(results_path)\n\n    in_exp = time.time()  # Start time for the overall experiment\n    best_models = open(results_path + \"/best_models.txt\", \"w\")  # Log best models\n    log_write = open(results_path + \"/log.txt\", \"w\")  # Log file\n\n    # Dataset and training parameters\n    dataset = dataset_conf.get('name')\n    n_classes = dataset_conf.get('n_classes')\n    n_sub = dataset_conf.get('n_sub')\n    data_path = dataset_conf.get('data_path')\n    isStandard = dataset_conf.get('isStandard')\n    LOSO = dataset_conf.get('LOSO')\n    include_cwt = dataset_conf.get('include_cwt')\n    batch_size = train_conf.get('batch_size')\n    model_name = train_conf.get('model')\n    lr = train_conf.get('lr')\n    epochs = train_conf.get('epochs')\n    n_train = train_conf.get('n_train')\n    from_logits = train_conf.get('from_logits')\n    frequencies = dataset_conf.get('cwt_frequencies')\n    sampling_frequency = dataset_conf.get('sampling_frequency')\n    LearnCurves = train_conf.get('LearnCurves')\n    classes_label = dataset_conf.get('cl_labels')\n    patience = train_conf.get('patience')\n\n    # Initialize arrays for storing training accuracy, kappa, test accuracy, kappa, and confusion matrices\n    test_acc = np.zeros((n_sub, n_train))\n    test_kappa = np.zeros((n_sub, n_train))\n    cf_matrix = np.zeros([n_sub, n_train, n_classes, n_classes])\n    test_precision = np.zeros((n_sub, n_train))\n    test_recall = np.zeros((n_sub, n_train))\n    test_f1 = np.zeros((n_sub, n_train))\n    inference_time = 0\n    \n    # Ensure a consistent seed is set\n    global_seed = 42\n    tf.random.set_seed(global_seed)\n    np.random.seed(global_seed)\n    random.seed(global_seed)\n    # os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Ensure deterministic operations\n  \n    for sub in tqdm(range(0,1), desc=\"Training and testing subjects\", unit=\"subject\"):\n        print(f'\\nTraining on subject {sub + 1}')\n        log_write.write(f'\\nTraining on subject {sub + 1}\\n')\n        BestSubjAcc = 0\n        bestTrainingHistory = []\n\n        # Get training and test data\n        X_train, _, y_train_onehot, X_test, _, y_test_onehot, X_train_cwt, X_test_cwt = get_data(\n            data_path, sub, frequencies, sampling_frequency, dataset=dataset, LOSO=LOSO, isStandard=isStandard, include_cwt=True\n        )\n\n        # Convert TensorFlow tensors to NumPy arrays if necessary\n        X_train = X_train.numpy() if hasattr(X_train, 'numpy') else X_train\n        y_train_onehot = y_train_onehot.numpy() if hasattr(y_train_onehot, 'numpy') else y_train_onehot\n        X_train_cwt = X_train_cwt.numpy() if hasattr(X_train_cwt, 'numpy') else X_train_cwt\n\n        # Augment the training data using your augmentation function\n        X_train_aug, X_train_cwt_aug, y_train_aug = time_and_cwt_augment(X_train, X_train_cwt, y_train_onehot)\n\n        # Convert to NumPy arrays if necessary\n        X_train_aug = X_train_aug.numpy() if hasattr(X_train_aug, 'numpy') else X_train_aug\n        y_train_aug = y_train_aug.numpy() if hasattr(y_train_aug, 'numpy') else y_train_aug\n        X_train_cwt_aug = X_train_cwt_aug.numpy() if hasattr(X_train_cwt_aug, 'numpy') else X_train_cwt_aug\n        # Print shapes after augmentation\n        print(f\"Augmented shapes:\")\n        print(f\"X_train_aug shape: {X_train_aug.shape}\")\n        print(f\"y_train_aug shape: {y_train_aug.shape}\")\n        print(f\"X_train_cwt_aug shape: {X_train_cwt_aug.shape}\")\n    \n        # Training loop with modifications\n        for train in tqdm(range(n_train), desc=f\"Training runs for subject {sub + 1}\", unit=\"run\"):\n            # Control the seed for each training run\n            #run_seed = train + global_seed\n            run_seed = global_seed\n            tf.random.set_seed(run_seed)\n            np.random.seed(run_seed)\n            random.seed(run_seed)\n            \n            in_run = time.time()\n            filepath = os.path.join(results_path, 'saved_models', f'run-{train + 1}', f'subject-{sub + 1}.weights.h5')\n            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n\n            # Create the model and set initial weights\n            model = getModel(model_name, dataset_conf, from_logits)\n            initial_weights = model.get_weights()  # Save initial weights\n            \n            # Print model input configuration (only for first subject's first run)\n            if sub == 0 and train == 0:\n                print(\"Model input configuration:\", model.inputs)\n                model.summary()\n                plot_model(model, to_file=os.path.join(results_path, 'model_summary.png'), show_shapes=True, show_layer_names=True)\n            \n            # Compile the model with gradient clipping\n            model.compile(\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=from_logits),\n                optimizer=tf.keras.optimizers.Adam(learning_rate=lr),  # Make sure lr is defined properly\n                metrics=['accuracy']\n            )\n\n            callbacks = [\n                tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max'),\n                tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),\n                tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, mode='max', patience=patience),\n                CustomTQDMProgressBar()  # Custom progress bar\n            ]\n            \n            # Load the initial weights before training each subject\n            model.set_weights(initial_weights)\n            \n            # Train the model\n            history = model.fit([X_train_aug, X_train_cwt_aug], y_train_aug,\n                                validation_data=([X_test, X_test_cwt], y_test_onehot),\n                                epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=0)\n\n            # Evaluate the best model on validation data\n            model.load_weights(filepath)\n\n            # Evaluate the model on test data\n            y_pred_test = model.predict([X_test, X_test_cwt])\n            if from_logits:\n                y_pred_test = tf.nn.softmax(y_pred_test).numpy().argmax(axis=-1)\n            else:\n                y_pred_test = y_pred_test.argmax(axis=-1)\n\n            labels_test = y_test_onehot.argmax(axis=-1)\n            test_acc[sub, train] = accuracy_score(labels_test, y_pred_test)\n            test_kappa[sub, train] = cohen_kappa_score(labels_test, y_pred_test)\n            test_precision[sub, train] = precision_score(labels_test, y_pred_test, average='weighted')\n            test_recall[sub, train] = recall_score(labels_test, y_pred_test, average='weighted')\n            test_f1[sub, train] = f1_score(labels_test, y_pred_test, average='weighted')\n            cf_matrix[sub, train, :, :] = confusion_matrix(labels_test, y_pred_test, normalize='true')\n\n            out_run = time.time()\n\n            # Log the performance after each run\n            info = f'Subject: {sub + 1}   seed {train + 1}   time: {(out_run - in_run) / 60:.1f} m   '\n            info += f'test_acc: {test_acc[sub, train]:.4f}  test_kappa: {test_kappa[sub, train]:.4f}  '\n            info += f'test_precision: {test_precision[sub, train]:.4f}  test_recall: {test_recall[sub, train]:.4f}  test_f1: {test_f1[sub, train]:.4f}'\n            print(info)\n            log_write.write(info + '\\n')\n            \n            # Save best run for the subject\n            if BestSubjAcc < test_acc[sub, train]:\n                BestSubjAcc = test_acc[sub, train]\n                bestTrainingHistory = history\n\n            # Clear GPU and RAM after each run\n            del history  # Remove large objects to free memory\n            K.clear_session()  # Clear TensorFlow session\n            gc.collect()  # Collect garbage to release memory\n            \n            # If GPU memory is utilized, reset GPU memory\n            if tf.config.experimental.get_visible_devices('GPU'):\n                tf.keras.backend.clear_session()  # Clear GPU memory\n                try:\n                    tf.config.experimental.set_memory_growth(tf.config.experimental.get_visible_devices('GPU')[0], True)\n                except:\n                    pass\n\n        # Test the best model after all runs\n        runs = os.listdir(results_path + \"/saved_models\")\n        X_test, X_test_cwt = np.array(X_test), np.array(X_test_cwt)\n        n_samples = X_test.shape[0]\n\n        for seed in range(len(runs)):\n            model.load_weights(f'{results_path}/saved_models/run-{seed + 1}/subject-{sub + 1}.weights.h5')\n            y_pred_test = []\n            start_time = time.time()\n\n            for i in range(0, n_samples, batch_size):\n                batch_end = min(i + batch_size, n_samples)\n                y_pred_batch = model.predict([X_test[i:batch_end], X_test_cwt[i:batch_end]]).argmax(axis=-1)\n                y_pred_test.extend(y_pred_batch)\n\n            inference_time += (time.time() - start_time) / n_samples\n\n            y_pred_test = np.array(y_pred_test)\n            labels_test = y_test_onehot.argmax(axis=-1)\n\n            # Compute metrics\n            precision = precision_score(labels_test, y_pred_test, average='weighted')\n            recall = recall_score(labels_test, y_pred_test, average='weighted')\n            f1 = f1_score(labels_test, y_pred_test, average='weighted')\n\n            test_precision[sub, seed] = precision\n            test_recall[sub, seed] = recall\n            test_f1[sub, seed] = f1\n            test_acc[sub, seed] = accuracy_score(labels_test, y_pred_test)\n            test_kappa[sub, seed] = cohen_kappa_score(labels_test, y_pred_test)\n            cf_matrix[sub, seed, :, :] = confusion_matrix(labels_test, y_pred_test, normalize='true')\n            \n            # Clean up after each seed-based evaluation\n            gc.collect()\n            K.clear_session()\n\n        # Logging and plotting results\n        best_run = np.argmax(test_acc[sub, :])  # Best run based on accuracy\n        best_models.write(f'subject-{sub + 1}.weights.h5 for run-{best_run + 1}\\n')\n        \n        # Load the best model weights for the best run\n        best_model_path = f'{results_path}/saved_models/run-{best_run + 1}/subject-{sub + 1}.weights.h5'\n        model.load_weights(best_model_path)\n\n        # Plot learning curves if required\n        if LearnCurves:\n            print('Plotting Learning Curves .......')\n            draw_learning_curves(bestTrainingHistory, sub + 1)\n            \n        draw_confusion_matrix(cf_matrix[sub, best_run, :, :], f'subject_{sub + 1}', results_path, classes_label)\n        print(f'Confusion matrix plotted for subject {sub + 1}.')\n        \n        # Define the feature extraction model\n        feature_model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('global_average_pooling1d').output)\n\n        # Get learned features for t-SNE\n        learned_features = feature_model.predict([X_test, X_test_cwt])\n        labels_test = y_test_onehot.argmax(axis=-1)  # True class labels\n\n        # Plot t-SNE using learned features\n        print(f\"Plotting t-SNE for learned features...\")\n        plot_tsne(learned_features, labels_test)\n        \n#        # Assuming 'model' is your trained model and you have a layer named 'ts__attention_module_1'\n#         attention_layer_name = 'ts__attention_module_1'\n#         attention_extractor = Model(inputs=model.input, \n#                                     outputs=model.get_layer(attention_layer_name).output)\n\n#         # Generate Attention Maps for a Batch of Test Data\n#         # Replace `attention_inputs` with the actual test inputs\n#         attention_maps = attention_extractor.predict([X_test, X_test_cwt])\n\n#         # Visualize Attention Maps for the First Sample in the Batch\n#         # Check the shape of attention_maps to understand its dimensions\n#         sample_attention_map = attention_maps[0]  # Select the first sample in the batch\n\n#         # Plotting the attention heatmap\n#         plt.figure(figsize=(10, 8))\n#         sns.heatmap(sample_attention_map, cmap='viridis')\n#         plt.title(f'Attention Map for Layer {attention_layer_name}')\n#         plt.xlabel('Key (input time steps/channels)')\n#         plt.ylabel('Query (output time steps/channels)')\n#         plt.show()\n\n        # After each subject\n        del X_train, y_train_onehot, X_train_cwt\n        del y_pred_test, labels_test, X_test, X_test_cwt, y_test_onehot\n        del X_train_aug, X_train_cwt_aug, y_train_aug\n        del model, bestTrainingHistory\n        gc.collect()\n        K.clear_session()\n        \n    # Timing the end of the experiment\n    out_exp = time.time()\n    # Prepare header for testing performance logging\n    head1_test = head2_test = '                '\n    for sub in range(n_sub): \n        head1_test += f'sub_{sub + 1}   '\n        head2_test += '-----   '\n    head1_test += ' average'\n    head2_test += ' -------'\n    \n    # Prepare test performance logging with additional metrics\n    test_info = f'\\n---------------------------------\\nTest performance (acc %, kappa, precision, recall, f1):\\n---------------------------------\\n{head1_test}\\n{head2_test}'\n    \n    # Print test performance for each seed and subject-wise\n    for run in range(n_train):  # Use n_train to ensure it matches the training runs\n        test_info += f'\\nSeed {run + 1}:'\n        test_info_acc = '(acc %)  '\n        test_info_k = '   (k-sco)      '\n        test_info_prec = '   (prec)       '\n        test_info_recall = '  (recall)      '\n        test_info_f1 = '    (f1)        '  \n        for sub in range(n_sub): \n            test_info_acc += f'{test_acc[sub, run] * 100:.2f}    '\n            test_info_k += f'{test_kappa[sub, run]:.3f}   '\n            test_info_prec += f'{test_precision[sub, run]:.3f}   '\n            test_info_recall += f'{test_recall[sub, run]:.3f}   '\n            test_info_f1 += f'{test_f1[sub, run]:.3f}   '\n        test_info_acc += f' {np.average(test_acc[:, run]) * 100:.2f}   '\n        test_info_k += f'  {np.average(test_kappa[:, run]):.3f}   '\n        test_info_prec += f'  {np.average(test_precision[:, run]):.3f}   '\n        test_info_recall += f'  {np.average(test_recall[:, run]):.3f}   '\n        test_info_f1 += f'  {np.average(test_f1[:, run]):.3f}   '   \n        test_info += test_info_acc + '\\n' + test_info_k + '\\n' + test_info_prec + '\\n' + test_info_recall + '\\n' + test_info_f1\n\n    # Subject-wise averages across all seeds\n    test_info += f'\\n\\nSubject-wise averages across all seeds:\\n'\n    test_info += ' (acc %)        '\n    test_info_kappa = '  (k-sco)       '\n    test_info_prec_avg = '  (prec)        '\n    test_info_recall_avg = '  (recall)      '\n    test_info_f1_avg = '    (f1)        '\n\n    subject_best_acc_list = []\n    subject_best_kappa_list = []\n    subject_best_prec_list = []\n    subject_best_recall_list = []\n    subject_best_f1_list = []\n\n    for sub in range(n_sub): \n        # Calculate averages\n        subject_avg_acc = np.average(test_acc[sub, :])\n        subject_avg_kappa = np.average(test_kappa[sub, :])\n        subject_avg_prec = np.average(test_precision[sub, :])\n        subject_avg_recall = np.average(test_recall[sub, :])\n        subject_avg_f1 = np.average(test_f1[sub, :])\n\n        test_info += f'{subject_avg_acc * 100:.2f}    '\n        test_info_kappa += f'{subject_avg_kappa:.3f}   '\n        test_info_prec_avg += f'{subject_avg_prec:.3f}   '\n        test_info_recall_avg += f'{subject_avg_recall:.3f}   '\n        test_info_f1_avg += f'{subject_avg_f1:.3f}   '\n\n        # Calculate best values for each subject\n        subject_best_acc_list.append(np.max(test_acc[sub, :]))\n        subject_best_kappa_list.append(np.max(test_kappa[sub, :]))\n        subject_best_prec_list.append(np.max(test_precision[sub, :]))\n        subject_best_recall_list.append(np.max(test_recall[sub, :]))\n        subject_best_f1_list.append(np.max(test_f1[sub, :]))\n\n    # Overall averages\n    test_info += f' {np.average(test_acc) * 100:.2f}   '\n    test_info_kappa += f'  {np.average(test_kappa):.3f}   '\n    test_info_prec_avg += f'  {np.average(test_precision):.3f}   '\n    test_info_recall_avg += f'  {np.average(test_recall):.3f}   '\n    test_info_f1_avg += f'  {np.average(test_f1):.3f}   '\n    test_info += '\\n' + test_info_kappa + '\\n' + test_info_prec_avg + '\\n' + test_info_recall_avg + '\\n' + test_info_f1_avg\n\n    # Display subject-wise best results\n    test_info += f'\\n\\nSubject-wise best results across all runs:\\n'\n    test_info += '  (best acc %)  '\n    test_info_kappa_best = '  (best k-sco)  '\n    test_info_prec_best = '  (best prec)   '\n    test_info_recall_best = '  (best recall) '\n    test_info_f1_best = '    (best f1)   '\n\n    for sub in range(n_sub):\n        test_info += f'{subject_best_acc_list[sub] * 100:.2f}    '\n        test_info_kappa_best += f'{subject_best_kappa_list[sub]:.3f}   '\n        test_info_prec_best += f'{subject_best_prec_list[sub]:.3f}   '\n        test_info_recall_best += f'{subject_best_recall_list[sub]:.3f}   '\n        test_info_f1_best += f'{subject_best_f1_list[sub]:.3f}   '\n\n    # Overall means of best scores\n    mean_best_acc = np.mean(subject_best_acc_list)\n    mean_best_kappa = np.mean(subject_best_kappa_list)\n    mean_best_prec = np.mean(subject_best_prec_list)\n    mean_best_recall = np.mean(subject_best_recall_list)\n    mean_best_f1 = np.mean(subject_best_f1_list)\n\n    test_info += f'  {mean_best_acc * 100:.2f}   '\n    test_info_kappa_best += f'  {mean_best_kappa:.3f}   '\n    test_info_prec_best += f'  {mean_best_prec:.3f}   '\n    test_info_recall_best += f'  {mean_best_recall:.3f}   '\n    test_info_f1_best += f'  {mean_best_f1:.3f}   '\n    test_info += '\\n' + test_info_kappa_best + '\\n' + test_info_prec_best + '\\n' + test_info_recall_best + '\\n' + test_info_f1_best\n\n    # Overall averages for testing performance\n    test_info += f'\\n----------------------------------\\nAverage - all seeds (acc %): {np.average(test_acc) * 100:.2f}\\n'\n    test_info += f'                    (k-sco): {np.average(test_kappa):.3f}\\n'\n    test_info += f'                    (prec):  {np.average(test_precision):.3f}\\n'\n    test_info += f'                    (recall):{np.average(test_recall):.3f}\\n'\n    test_info += f'                    (f1):    {np.average(test_f1):.3f}\\n'\n    test_info += f'\\nSubject-wise best average (acc %): {mean_best_acc*100:.2f}\\n'\n    test_info += f'                          (k-sco): {mean_best_kappa:.3f}\\n'\n    test_info += f'                          (prec):  {mean_best_prec:.3f}\\n'\n    test_info += f'                          (recall):{mean_best_recall:.3f}\\n'\n    test_info += f'                           (f1):   {mean_best_f1:.3f}\\n'\n    test_info += f'\\nInference time: {inference_time / len(runs):.2f} ms per trial\\n'\n    test_info += '----------------------------------\\n'\n\n    # Final output\n    info = test_info\n\n    # Print final results and write to log file\n    print(info)\n    log_write.write(info + '\\n')\n\n    # Save confusion matrices and inference time\n    np.save(os.path.join(results_path, 'confusion_matrix.npy'), cf_matrix)\n    np.save(os.path.join(results_path, 'inference_time.npy'), inference_time)\n    np.save(os.path.join(results_path, 'precision.npy'), test_precision)\n    np.save(os.path.join(results_path, 'recall.npy'), test_recall)\n    np.save(os.path.join(results_path, 'f1_score.npy'), test_f1)\n    \n    draw_performance_barChart(n_sub, subject_best_acc_list, 'Testing Accuracy', mean_best_acc)\n    draw_performance_barChart(n_sub, subject_best_kappa_list, 'Testing Kappa Score', mean_best_kappa)\n    draw_performance_barChart(n_sub, subject_best_prec_list, 'Testing Precision', mean_best_prec)\n    draw_performance_barChart(n_sub, subject_best_recall_list, 'Testing Recall', mean_best_recall)\n    draw_performance_barChart(n_sub, subject_best_f1_list, 'Testing F1-Score', mean_best_f1)\n    draw_confusion_matrix(cf_matrix.mean((0, 1)), 'All', results_path, classes_labels)\n    \n    # Close log files    \n    best_models.close()   \n    log_write.close()\n\n    # Total experiment time\n    print(f'\\nTotal Experiment Time: {(time.time() - in_exp) / 60:.1f} minutes.')\n    \n#%%\ndef getModel(model_name, dataset_conf, from_logits = False):\n    \n    n_classes = dataset_conf.get('n_classes')\n    n_channels = dataset_conf.get('n_channels')\n    in_samples = dataset_conf.get('in_samples')\n    frequencies = dataset_conf.get('cwt_frequencies') \n\n    # Select the model\n    if(model_name == 'TSxTF'):\n        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n        model = TSxTF( \n            # Dataset parameters\n            n_classes = n_classes, \n            in_chans = n_channels, \n            in_samples = in_samples,\n            frequencies= frequencies,\n            # Convolutional (CV) block parameters\n            eegn_F1 = 16,\n            eegn_D = 2, \n            eegn_kernelSize = 64,\n            eegn_poolSize = 7,\n            eegn_dropout = 0.3,\n            # Temporal convolutional (TC) block parameters\n            tcn_depth = 2, \n            tcn_kernelSize = 4,\n            tcn_filters = 32,\n            tcn_dropout = 0.3, \n            tcn_activation='elu',\n            )     \n    else:\n        raise Exception(\"'{}' model is not supported yet!\".format(model_name))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:24.394142Z","iopub.execute_input":"2024-11-14T20:02:24.394472Z","iopub.status.idle":"2024-11-14T20:02:24.486136Z","shell.execute_reply.started":"2024-11-14T20:02:24.394437Z","shell.execute_reply":"2024-11-14T20:02:24.485273Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Frequency Generator","metadata":{}},{"cell_type":"code","source":"def generate_frequencies(total_frequencies):\n    # Define the distribution percentages\n    band_percentages = {\n        '0.5-8 Hz': 0.05,    # 5% between 0 and 8 Hz\n        '8-30 Hz': 0.40,   # 60% between 8 and 40 Hz\n        '30-50 Hz': 0.30,  # 10% between 40 and 60 Hz\n        '50-85 Hz': 0.05,  # 5% between 60 and 80 Hz\n        '85-100 Hz': 0.15  # 20% between 80 and 100 Hz\n    }\n\n    # Calculate the number of frequencies for each band\n    count_0_8 = int(total_frequencies * band_percentages['0.5-8 Hz'])\n    count_8_40 = int(total_frequencies * band_percentages['8-30 Hz'])\n    count_40_60 = int(total_frequencies * band_percentages['30-50 Hz'])\n    count_60_80 = int(total_frequencies * band_percentages['50-85 Hz'])\n    count_80_100 = total_frequencies - (count_0_8 + count_8_40 + count_40_60 + count_60_80)  # Remaining for 80-100 Hz\n\n    # Generate frequencies for each band\n    band_0_8 = np.linspace(0.5, 8, count_0_8, endpoint=False)         # Frequencies between 0 and 8 Hz\n    band_8_40 = np.linspace(8, 30, count_8_40, endpoint=False)       # Frequencies between 8 and 40 Hz\n    band_40_60 = np.linspace(30, 50, count_40_60, endpoint=False)    # Frequencies between 40 and 60 Hz\n    band_60_80 = np.linspace(50, 85, count_60_80, endpoint=False)    # Frequencies between 60 and 80 Hz\n    band_80_100 = np.linspace(85, 100.5, count_80_100, endpoint=False) # Frequencies between 80 and 100 Hz\n\n    # Combine all frequencies\n    frequencies = np.concatenate((band_0_8, band_8_40, band_40_60, band_60_80, band_80_100))\n\n    # Sort frequencies (just in case, though it should already be sorted)\n    frequencies = np.sort(frequencies)\n\n    return frequencies\n\n# Example usage:\ntotal_frequencies = 32  # You can change this to any number of total frequencies\nfrequencies = generate_frequencies(total_frequencies)\n\n# print(frequencies)\n# print(f\"Total frequencies: {len(frequencies)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:24.487431Z","iopub.execute_input":"2024-11-14T20:02:24.487742Z","iopub.status.idle":"2024-11-14T20:02:24.498987Z","shell.execute_reply.started":"2024-11-14T20:02:24.487710Z","shell.execute_reply":"2024-11-14T20:02:24.498050Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Run Train_Test","metadata":{}},{"cell_type":"code","source":"in_samples = 1000\nn_channels = 22\nn_sub = 9\nn_classes = 4\nclasses_labels = ['Left hand', 'Right hand','Foot','Tongue']\ndata_path ='/kaggle/input/bcic-iv-2amatlab-version/'\ndataset = 'BCI2a'\nlr = 0.0009\n\n# Create a folder to store the results of the experiment\nresults_path = os.getcwd() + \"/results\"\nif not  os.path.exists(results_path):\n      os.makedirs(results_path)   # Create a new directory if it does not exist \n    \n    # Set dataset paramters \n# Set dataset parameters\ndataset_conf = {\n    'name': dataset,\n    'n_classes': n_classes,\n    'cl_labels': classes_labels,\n    'n_sub': n_sub,\n    'n_channels': n_channels,\n    'in_samples': in_samples,\n    'data_path': data_path,\n    'cwt_frequencies': frequencies,  # CWT frequency range from 0.5 to 100 Hz \n    'isStandard': True,\n    'LOSO': False,\n    'include_cwt': True,\n    'sampling_frequency': 250  # Raw EEG signal sampling frequency\n}\n\ntrain_conf = { 'batch_size': 64, 'epochs': 1000, 'patience': 300, 'lr': lr,'n_train': 10,\n                  'LearnCurves': True, 'from_logits': False, 'model':'TSxTF'}\n    \nresults_path= '/kaggle/working/results'\n# Call the training function\ntrain_and_test(dataset_conf,train_conf, results_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T20:02:24.500279Z","iopub.execute_input":"2024-11-14T20:02:24.500588Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Training and testing subjects:   0%|          | 0/1 [00:00<?, ?subject/s]","output_type":"stream"},{"name":"stdout","text":"\nTraining on subject 1\nX_train shape: (288, 1, 22, 1000), X_test shape: (288, 1, 22, 1000)\ny_train_onehot shape: (288, 4), y_test_onehot shape: (288, 4)\nX_train_cwt shape: (288, 32, 1000, 22), X_test_cwt shape: (288, 32, 1000, 22)\nAugmented shapes:\nX_train_aug shape: (1440, 1, 22, 1000)\ny_train_aug shape: (1440, 4)\nX_train_cwt_aug shape: (1440, 32, 1000, 22)\n","output_type":"stream"},{"name":"stderr","text":"\nTraining runs for subject 1:   0%|          | 0/10 [00:00<?, ?run/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Model input configuration: [<KerasTensor shape=(None, 1, 22, 1000), dtype=float32, sparse=None, name=keras_tensor>, <KerasTensor shape=(None, 32, 1000, 22), dtype=float32, sparse=None, name=keras_tensor_1>]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1000\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m22\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transpose_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mTransposeLayer\u001b[0m)    │ \u001b[38;5;34m1000\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ separable_conv2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │     \u001b[38;5;34m26,016\u001b[0m │ transpose_layer[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ separable_conv2d… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m22\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1000\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu (\u001b[38;5;33mELU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ depthwise_conv2d_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │        \u001b[38;5;34m368\u001b[0m │ elu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │      \u001b[38;5;34m1,024\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │      \u001b[38;5;34m1,280\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │        \u001b[38;5;34m768\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ depthwise_conv2d… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_1 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average (\u001b[38;5;33mAverage\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m22\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │ batch_normalizat… │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ elu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ depthwise_conv2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1\u001b[0m,   │        \u001b[38;5;34m704\u001b[0m │ average[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │        \u001b[38;5;34m544\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ depthwise_conv2d… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_2 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │      \u001b[38;5;34m4,128\u001b[0m │ elu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_3 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ elu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │      \u001b[38;5;34m1,056\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m128\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_4 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m3,104\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ squeeze_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ elu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mSqueezeLayer\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │ squeeze_layer[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m23\u001b[0m)    │        \u001b[38;5;34m759\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m23\u001b[0m)    │         \u001b[38;5;34m46\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ts__attention_modu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,224\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mTS_AttentionModul…\u001b[0m │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                     │                   │            │ ts__attention_mo… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,128\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                     │                   │            │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gated_linear_unit   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout1… │\n│ (\u001b[38;5;33mGatedLinearUnit\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,080\u001b[0m │ gated_linear_uni… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout1… │\n│                     │                   │            │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,128\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gated_linear_unit_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout1… │\n│ (\u001b[38;5;33mGatedLinearUnit\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,080\u001b[0m │ gated_linear_uni… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout1… │\n│                     │                   │            │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m132\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ softmax             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transpose_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransposeLayer</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ separable_conv2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,016</span> │ transpose_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ separable_conv2d… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ depthwise_conv2d_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">368</span> │ elu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ depthwise_conv2d… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │ batch_normalizat… │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ elu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ depthwise_conv2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ average[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ depthwise_conv2d… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ elu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ elu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ elu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ squeeze_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ elu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeLayer</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │ squeeze_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">759</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ts__attention_modu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TS_AttentionModul…</span> │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                     │                   │            │ ts__attention_mo… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                     │                   │            │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gated_linear_unit   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GatedLinearUnit</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gated_linear_uni… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1… │\n│                     │                   │            │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gated_linear_unit_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GatedLinearUnit</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ gated_linear_uni… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ spatial_dropout1d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1… │\n│                     │                   │            │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ softmax             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,841\u001b[0m (323.60 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,841</span> (323.60 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,105\u001b[0m (320.72 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,105</span> (320.72 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m736\u001b[0m (2.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> (2.88 KB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"Epochs:   0%|          | 0/1000 [00:00<?, ?epoch/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1731614726.307984     103 service.cc:145] XLA service 0x7d1a20004890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1731614726.308041     103 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1731614755.557927     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nEpoch 17, Train Acc: 0.9812, Valid Acc: 0.3715, Valid Loss: 4.9629, Best Valid Acc: 0.3715 (Epoch 16), Best Valid Loss: 4.9629 (Epoch 17):   2%|▏         | 17/1000 [02:10<57:26,  3.51s/epoch]  ","output_type":"stream"}]}]}